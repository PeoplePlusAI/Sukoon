# -*- coding: utf-8 -*-
"""TextGrad Sukoon.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10Zq48yr44O2mHGmUrhyJNnVWuwDBWlRh
"""

# !pip install textgrad
import textgrad as tg
import os
from dotenv import load_dotenv, find_dotenv
_ = load_dotenv(find_dotenv())
# os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY

model = "gpt-4o" # gpt-3.5-turbo
tg.set_backward_engine(model, override=True)

# Step 1: Get an initial response from an LLM.
'''
Initialize the LLM module.
:param engine: The language model engine to use.
:type engine: EngineLM
:param system_prompt: The system prompt variable, defaults to None.
:type system_prompt: Variable, optional
'''
model = tg.BlackboxLLM(engine="gpt-4o-mini", system_prompt = "You are Sukoon...") # , system_prompt = "You are Sukoon..."
question_string = ("I've been feeling really down lately and I don't know why. Nothing seems to make me happy anymore.")

question = tg.Variable(question_string,
                       role_description="question to the LLM",
                       requires_grad=False)

answer = model(question)

print(answer.value)

# answer.value = "I'm sorry to hear that you've been feeling down. It's not uncommon to experience periods of low mood, and it can be frustrating when you can't pinpoint the reason. Have you noticed any changes in your daily routine or any recent stressful events? Sometimes, talking to a mental health professional can help you explore these feelings and find ways to cope. Would you like to discuss some simple self-care strategies that might help lift your mood?"

# updating the answer
answer.set_role_description("emphathetic and helpful answer to the question")

# Step 2: Define the loss function and the optimizer, just like in PyTorch!
# Here, we don't have SGD, but we have TGD (Textual Gradient Descent)
# that works with "textual gradients".
optimizer = tg.TGD(parameters=[answer]) #optimizer_system_prompt: str = OPTIMIZER_SYSTEM_PROMPT, in_context_examples: List[str] = None

evaluation_instruction = (f"Here's a question: {question_string}. "
                           "Evaluate any given answer to this question, "
                           "be smart, logical, and very critical. "
                           "Just provide concise feedback within 50 words."
                           "identify strengths, areas for improvement, and suggest followup questions")

# TextLoss is a natural-language specified loss function that describes
# how we want to evaluate the reasoning.
loss_fn = tg.TextLoss(evaluation_instruction)

loss = loss_fn(answer)

print(loss.value)
'''
Strengths:
- Empathetic and validating response.
- Offers practical suggestions for self-care.
- Encourages seeking professional help.

Areas for Improvement:
- Could be more concise.
- Lacks specific follow-up questions to delve deeper into the issue.

Suggested Follow-up Questions:
- "Have you experienced any significant changes in your life recently?"
- "How long have you been feeling this way?"
- "Have you tried any activities that previously made you happy?
"'''

# Step 3: Do the loss computation, backward pass, and update the punchline.
# Exact same syntax as PyTorch!
# loss = loss_fn(answer)
loss.backward() # main step where textual loss gradient propogates backward
optimizer.step() # correction in answer

updated_answer = answer
print(f"\n\n\n\n The updated answer is {updated_answer}")